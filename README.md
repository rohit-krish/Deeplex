Deeplex is a basic Deep Learning Framework, built on top of an AutoGrad Engine.

### TODO

- [x] computation on GPU aswell
- [ ] add .requires_grad in Tensor & Scaler
- [ ] add the 'with block' of no_grad
- [ ] automatically list the parameters
- [ ] implement more loss functions
- [x] Adam, RMSProp, SGD+Momentum
- [ ] learning rate schedulers
- [ ] weight initializations
- [ ] Conv2d, RNN, LSTM, GRU
- [ ] dataloader
- [ ] testes
- [ ] add docs inside code
- [ ] update README.md
- [ ] add setup.py
- etc...

### Resources

- https://youtu.be/wG_nF1awSSY (What is Automatic Differentiation?)
- https://youtu.be/VMj-3S1tku0 (The spelled-out intro to neural networks and backpropagation: building micrograd)
- https://youtu.be/pauPCy_s0Ok (Neural Network from Scratch | Mathematics & Python Code)
- https://github.com/conscell/ugrad (A lightweight automatic differentiation engine)
